spring.application.name=mcp
spring.main.web-application-type=none

# Disable the chat client auto-configuration because we are using multiple chat models
spring.ai.chat.client.enabled=false

# OpenAI Configuration
spring.ai.openai.api-key=${OPENAI_API_KEY}

# Ollama Configuration
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=llama3.2
spring.ai.ollama.chat.options.temperature=0.7

# MCP Client Configuration
spring.ai.mcp.client.sse.connections.server1.url=http://localhost:8080

# Logging Configuration
logging.level.io.modelcontextprotocol.client=WARN
logging.level.io.modelcontextprotocol.spec=WARN

spring.ai.mcp.client.toolcallback.enabled=false